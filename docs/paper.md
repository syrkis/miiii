---
title: Mechanistic Interpretability on Irreducible Integers
author: Noah Syrkis
---

\begin{abstract}
We apply the mechanistic interpretability framework to a transformer model trained on a dataset of irreducible integers. We show that the model has learned to perform modular addition, and we reverse-engineer the model to understand how it does so.
\end{abstract}

# Introduction

Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.
Reverse-engineerings deep neural networks (DNN) is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.



Mechanistic interpretability (MI) posits that deep neural networks (DNN) are circuits that can be reverse-engineered to understand their inner workings. MI is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.

Mechanistic interpretability (MI) posits that deep neural networks (DNN) are circuits that can be reverse-engineered to understand their inner workings. MI is a relatively new field, but has already shown success. For example, reverse engineers a transformer model to understand how it performs modular addition. attempts to automate the reverse-engineering process, and is somewhat successful.

# Background

## Transformer models

As artificial intelligence systems 
Mechanistic interpretability (MI) posits that deep neural networks (DNN) are circuits that can be reverse-engineered to understand their inner workings. MI is a relatively new field, but has already shown success. For example, @nanda2023 reverse engineers a transformer model [@vaswani2017] to understand how it performs modular addition.
@cover2006 attempts to automate the reverse-engineering process, and is somewhat successful.
However, the process is still largely manual and requires a deep understanding of the model's architecture and training process. Leveraging the transformer model's attention mechanism, @conmy2023 attempts to automate the reverse-engineering process, and is somewhat successful. 
@conmy2023 attempts to automate the reverse-engineering process, and is somewhat successful, while @belcak2022 diconfirms this.

In this paper, we apply the MI framework to a transformer model trained on a dataset of irreducible integers. We show that the model has learned to perform modular addition, and we reverse-engineer the model to understand how it does so.

## Mechanistic interpretability

Mechanistic interpretability (MI) posits that deep neural networks (DNN) are circuits that can be reverse-engineered to understand their inner workings. MI is a relatively new field, but has already shown success. For example, @nanda2023 reverse engineers a transformer model [@vaswani2017] to understand how it performs modular addition.

## Irreducible integers

Irreducible integers are primes, though thet are described as such so as to allo the title of the paper to be a reference to Douglas Hofstades MIU puzzle.


# Methodology

Our methodology consists of the following steps:


## Data


Here's a table:

\atable{data.csv}{Dataset}{data}

The dataset consists of four-digit integers and their labels. The labels are 1 if the integer is irreducible, and 0 otherwise. The dataset is generated by taking all four-digit integers and checking if they are irreducible. The dataset is then split into a training set and a test set.



## Model

The model is a transformer model in the style of @hu2023. It is trained on the dataset above.

## Reverse-engineering

We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.

\atable{data.csv}{Dataset}{data}{wide}


# Results

We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.
We reverse-engineer the model by analyzing the attention weights. We show that the model has learned to perform modular addition.

## Circuits

We see these circuits:

- Circuit 1
- Circuit 2
- Circuit 3


## Attention weights

We see these attention weights:

- Attention weight 1
- Attention weight 2


## Modular addition

We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.
We show that the model has learned to perform modular addition.


# Analysis

Lorem Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint obcaecat cupiditat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. 

\afigure{attn.png}{Attention}{attn}

## Interpretability

Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint obcaecat cupiditat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. 

## Generalization

Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint obcaecat cupiditat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. 

# Conclusion

Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint obcaecat cupiditat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. 